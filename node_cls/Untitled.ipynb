{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy import io\n",
    "import networkx as nx\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"Case_Based\":0,\n",
    "    \"Genetic_Algorithms\":1,\n",
    "    \"Neural_Networks\":2,\n",
    "    \"Probabilistic_Methods\":3,\n",
    "    \"Reinforcement_Learning\":4,\n",
    "    \"Rule_Learning\": 5,\n",
    "    \"Theory\":6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path=\"cora/\", dataset=\"cora\"):\n",
    "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
    "    print('Loading {} dataset...'.format(dataset))\n",
    "\n",
    "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
    "                                        dtype=np.dtype(str))\n",
    "    \n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
    "    labels = idx_features_labels[:, -1]\n",
    "\n",
    "    # build graph\n",
    "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "    idx_map = {j: i for i, j in enumerate(idx)}\n",
    "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
    "                                    dtype=np.int32)\n",
    "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]),\n",
    "                        dtype=np.float32)\n",
    "\n",
    "    # build symmetric adjacency matrix\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "    features = normalize(features)\n",
    "    #adj = normalize(adj + sp.eye(adj.shape[0]))\n",
    "    labels_int = [label_map[f] for f in idx_features_labels[:, -1]]\n",
    "    \n",
    "    idx_train = range(1000)\n",
    "    idx_val = None\n",
    "    idx_test = range(1000, 1500)\n",
    "\n",
    "    return adj, features, labels_int, idx_train, idx_val, idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    }
   ],
   "source": [
    "adj, features, labels, idx_train, idx_val, idx_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_scipy_sparse_matrix(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = \"CORA\"\n",
    "datadir  = \"cora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count, test_count = 0,0\n",
    "train_tk, test_tk = [],[]\n",
    "node_vocab = []\n",
    "\n",
    "for idx in range(1500):\n",
    "    G_sub = nx.ego_graph(G, idx, radius=3)\n",
    "    node_ids = [labels[n] for n in G_sub.nodes]\n",
    "    if len(node_ids) > max_len-1:\n",
    "        continue\n",
    "        \n",
    "    # ADJ\n",
    "    if idx in idx_train:\n",
    "        fname = str(train_count)+'_'+dataname+\"_adj.mtx\"\n",
    "    else:\n",
    "        fname = str(test_count)+'_'+dataname+\"_adj_val.mtx\"\n",
    "        \n",
    "    G_u = G_sub.to_undirected()\n",
    "    adj = nx.adj_matrix(G_u).todense()\n",
    "    final = np.zeros((max_len,max_len), dtype=int)\n",
    "    final[1:adj.shape[0]+1, 1:adj.shape[1]+1] = adj\n",
    "    final += np.eye(max_len, dtype=int)\n",
    "    final[:,0] = np.ones(max_len)\n",
    "    final[0,:] = np.ones(max_len)\n",
    "\n",
    "    m = sp.csr_matrix(final)\n",
    "    sparsedir = os.path.join(datadir, 'adj')\n",
    "    if not os.path.exists(sparsedir):\n",
    "        os.makedirs(sparsedir)\n",
    "    io.mmwrite(os.path.join(sparsedir, fname), m)\n",
    "    \n",
    "    if idx in idx_train:\n",
    "        train_count+= 1\n",
    "    else:\n",
    "        test_count += 1\n",
    "        \n",
    "    for w in node_ids:\n",
    "        if w not in node_vocab:\n",
    "            node_vocab.append(w)\n",
    "    node_ids.insert(0,'[CLS]')\n",
    "    if idx in idx_train:\n",
    "        train_tk.append(node_ids)\n",
    "    else:\n",
    "        test_tk.append(node_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541, 322)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count, test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir, dataname+'-vocab.txt'), 'w') as f:       \n",
    "    for i in range(np.max(node_vocab)+1):\n",
    "        f.write(str(i)+'\\n')\n",
    "    f.write(\"[CLS]\"+'\\n')\n",
    "    f.write(\"[MASK]\"+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir, dataname+'_tk.txt'), 'w') as f:\n",
    "    w = csv.writer(f, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for tk in train_tk:\n",
    "        w.writerow(tk)\n",
    "        w.writerow([])\n",
    "    \n",
    "\n",
    "with open(os.path.join(datadir, dataname+'_tk_val.txt'), 'w') as f:\n",
    "    w = csv.writer(f, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for tk in test_tk:\n",
    "        w.writerow(tk)\n",
    "        w.writerow([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
