{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '../../bert-cmp/bert/'\n",
    "path = '../sparse/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "      <th>360</th>\n",
       "      <th>361</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "      <th>365</th>\n",
       "      <th>366</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.901069</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.003034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>0.003306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.001528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000399  0.000342  0.000380  0.000350  0.000264  0.901069  0.000240   \n",
       "1  0.001290  0.010545  0.001825  0.001661  0.001313  0.002090  0.003562   \n",
       "2  0.001876  0.001126  0.001211  0.001370  0.000909  0.001858  0.007690   \n",
       "3  0.001275  0.001973  0.002989  0.002538  0.001087  0.001204  0.003934   \n",
       "4  0.000277  0.000125  0.000194  0.000210  0.000132  0.000287  0.000062   \n",
       "5  0.000022  0.000036  0.000129  0.000030  0.000015  0.000014  0.000078   \n",
       "6  0.000186  0.000095  0.000106  0.000147  0.000121  0.000128  0.000161   \n",
       "7  0.000012  0.000010  0.000010  0.000020  0.000005  0.000028  0.000029   \n",
       "8  0.001692  0.003752  0.003454  0.003444  0.002472  0.003625  0.000944   \n",
       "9  0.001016  0.000847  0.003369  0.000925  0.001630  0.001927  0.001444   \n",
       "\n",
       "        7         8         9    ...       357       358       359       360  \\\n",
       "0  0.000356  0.000324  0.000321  ...  0.000367  0.000254  0.000216  0.000254   \n",
       "1  0.002553  0.001355  0.002622  ...  0.001841  0.001863  0.002519  0.002107   \n",
       "2  0.001698  0.002108  0.002983  ...  0.001680  0.001365  0.001057  0.001036   \n",
       "3  0.001867  0.002137  0.002371  ...  0.001544  0.001922  0.001250  0.001026   \n",
       "4  0.000218  0.000128  0.000106  ...  0.000114  0.000146  0.000112  0.000257   \n",
       "5  0.000027  0.000014  0.000038  ...  0.000016  0.000034  0.000020  0.000031   \n",
       "6  0.000057  0.000084  0.000214  ...  0.000068  0.000160  0.000055  0.000192   \n",
       "7  0.000011  0.000008  0.000014  ...  0.000011  0.000014  0.000010  0.000016   \n",
       "8  0.001508  0.002216  0.001201  ...  0.001808  0.001405  0.001708  0.001684   \n",
       "9  0.000537  0.001437  0.002805  ...  0.000596  0.002927  0.000406  0.001699   \n",
       "\n",
       "        361       362       363       364       365       366  \n",
       "0  0.000255  0.000204  0.000170  0.000160  0.000138  0.000333  \n",
       "1  0.003121  0.001771  0.002401  0.001852  0.001286  0.003034  \n",
       "2  0.001565  0.001407  0.002132  0.001676  0.002545  0.001386  \n",
       "3  0.001532  0.001392  0.002205  0.001938  0.004727  0.003306  \n",
       "4  0.000126  0.000125  0.000118  0.000104  0.000182  0.000159  \n",
       "5  0.000032  0.000020  0.000032  0.000019  0.000057  0.000021  \n",
       "6  0.000149  0.000059  0.000137  0.000067  0.000054  0.000072  \n",
       "7  0.000021  0.000012  0.000010  0.000010  0.000024  0.000014  \n",
       "8  0.001530  0.001408  0.001554  0.001364  0.001991  0.001528  \n",
       "9  0.001538  0.000548  0.001320  0.000408  0.000711  0.001013  \n",
       "\n",
       "[10 rows x 367 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv(path+'cls_output/test_results.tsv', header=None, sep='\\t')\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 367)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 1)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_label_df = pd.read_csv(path+'sparse_fname2_vocab-label.txt', header=None)\n",
    "vocab_label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "preds = []\n",
    "for idx, row in results_df.iterrows():\n",
    "    top_n = list(np.argsort(-row)[:n])\n",
    "    preds.append(top_n[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 325, 326, 25, 327, 27, 147, 93, 211, 241],\n",
       " [12, 13, 324, 1, 106, 317, 139, 105, 107, 243],\n",
       " [17, 18, 25, 16, 50, 72, 6, 65, 20, 47],\n",
       " [25, 225, 12, 50, 248, 82, 190, 226, 88, 187],\n",
       " [27, 110, 340, 73, 223, 70, 337, 182, 174, 76],\n",
       " [12, 50, 17, 143, 207, 226, 25, 182, 2, 242],\n",
       " [24, 242, 50, 183, 240, 72, 137, 156, 136, 124],\n",
       " [25, 12, 134, 72, 327, 49, 148, 242, 226, 62],\n",
       " [32, 31, 28, 30, 33, 129, 197, 194, 24, 215],\n",
       " [50, 24, 53, 138, 47, 49, 72, 240, 352, 205],\n",
       " [12, 24, 111, 71, 68, 110, 308, 147, 13, 117],\n",
       " [12, 6, 207, 143, 226, 242, 198, 25, 308, 91],\n",
       " [16, 50, 75, 18, 20, 12, 36, 82, 13, 135],\n",
       " [101, 5, 12, 18, 64, 327, 306, 268, 326, 69],\n",
       " [110, 111, 121, 365, 115, 138, 226, 27, 109, 56],\n",
       " [111, 110, 119, 206, 137, 116, 121, 118, 64, 108],\n",
       " [12, 25, 143, 207, 6, 198, 242, 50, 226, 17],\n",
       " [123, 166, 195, 224, 77, 250, 6, 193, 297, 141],\n",
       " [50, 53, 24, 138, 47, 12, 352, 135, 240, 137],\n",
       " [128, 129, 127, 211, 16, 137, 138, 189, 30, 68],\n",
       " [128, 129, 127, 211, 16, 137, 138, 189, 30, 68],\n",
       " [128, 129, 127, 211, 16, 137, 138, 189, 30, 68],\n",
       " [129, 128, 127, 130, 211, 218, 123, 195, 238, 16],\n",
       " [50, 24, 53, 138, 137, 47, 2, 224, 352, 135],\n",
       " [50, 53, 24, 138, 12, 135, 157, 47, 137, 244],\n",
       " [12, 25, 143, 207, 198, 50, 242, 6, 226, 223],\n",
       " [49, 299, 259, 157, 124, 73, 145, 137, 150, 233],\n",
       " [141, 142, 349, 134, 47, 353, 235, 227, 177, 133],\n",
       " [134, 25, 47, 142, 132, 136, 72, 168, 206, 135],\n",
       " [25, 12, 72, 327, 134, 6, 248, 62, 82, 50],\n",
       " [12, 25, 147, 143, 50, 198, 207, 226, 242, 153],\n",
       " [12, 50, 143, 207, 25, 198, 237, 242, 153, 226],\n",
       " [138, 50, 137, 157, 209, 110, 280, 173, 114, 317],\n",
       " [25, 12, 134, 49, 72, 226, 327, 62, 242, 224],\n",
       " [50, 53, 12, 147, 135, 24, 352, 140, 47, 138],\n",
       " [25, 12, 72, 134, 327, 148, 6, 62, 82, 248],\n",
       " [53, 50, 138, 218, 108, 124, 47, 296, 43, 248],\n",
       " [27, 110, 223, 73, 70, 340, 137, 76, 99, 182],\n",
       " [136, 137, 24, 43, 305, 201, 49, 181, 73, 142],\n",
       " [50, 53, 12, 138, 135, 200, 244, 352, 140, 24],\n",
       " [50, 53, 12, 138, 135, 200, 244, 352, 140, 24],\n",
       " [146, 240, 206, 309, 271, 198, 162, 40, 239, 95],\n",
       " [156, 24, 256, 12, 157, 183, 154, 146, 123, 158],\n",
       " [12, 143, 207, 226, 198, 242, 25, 237, 6, 223],\n",
       " [12, 50, 53, 143, 207, 226, 25, 198, 6, 47],\n",
       " [49, 124, 145, 25, 50, 73, 203, 12, 43, 136],\n",
       " [24, 227, 271, 222, 70, 72, 216, 106, 274, 207],\n",
       " [277, 174, 171, 172, 93, 221, 179, 318, 230, 177],\n",
       " [220, 222, 176, 221, 225, 241, 256, 72, 238, 286],\n",
       " [265, 72, 282, 252, 12, 168, 237, 173, 177, 185],\n",
       " [190, 12, 50, 272, 226, 237, 299, 225, 216, 213],\n",
       " [203, 202, 130, 269, 199, 215, 211, 270, 175, 214],\n",
       " [203, 202, 215, 269, 130, 254, 255, 205, 169, 271],\n",
       " [12, 25, 50, 226, 17, 242, 143, 207, 124, 64],\n",
       " [240, 24, 50, 2, 175, 250, 206, 146, 363, 211],\n",
       " [76, 27, 355, 11, 18, 7, 65, 73, 10, 43],\n",
       " [188, 189, 256, 249, 24, 252, 222, 176, 271, 170],\n",
       " [173, 138, 128, 189, 289, 175, 286, 220, 221, 223],\n",
       " [191, 194, 192, 195, 193, 198, 197, 196, 200, 43],\n",
       " [209, 100, 203, 144, 202, 238, 366, 6, 219, 200],\n",
       " [271, 267, 238, 239, 130, 203, 62, 200, 280, 220],\n",
       " [173, 189, 220, 72, 221, 170, 227, 286, 241, 5],\n",
       " [216, 276, 190, 274, 254, 50, 264, 170, 207, 204],\n",
       " [174, 177, 70, 254, 115, 27, 346, 110, 137, 248],\n",
       " [185, 186, 187, 189, 180, 145, 12, 167, 5, 198],\n",
       " [189, 227, 188, 280, 279, 178, 286, 276, 17, 89],\n",
       " [253, 207, 110, 35, 177, 170, 216, 109, 41, 262],\n",
       " [195, 194, 191, 197, 193, 192, 198, 196, 199, 200],\n",
       " [182, 279, 24, 4, 50, 32, 255, 361, 273, 31],\n",
       " [106, 244, 248, 53, 40, 195, 9, 331, 297, 226],\n",
       " [280, 281, 279, 227, 282, 106, 127, 271, 1, 103],\n",
       " [213, 198, 12, 242, 208, 176, 225, 197, 101, 196],\n",
       " [106, 361, 213, 107, 105, 271, 88, 332, 4, 272],\n",
       " [327, 6, 25, 326, 200, 243, 199, 194, 2, 169],\n",
       " [318, 27, 25, 49, 341, 134, 338, 47, 342, 340]]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_csv(path+'sparse_fname_split_magret_label_val.txt', header=None)\n",
    "label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= []; labels_str =[]\n",
    "for idx, row in label_df.iterrows():\n",
    "    labels.append(vocab_label_df.index[vocab_label_df[0]==row[0]][0])\n",
    "    labels_str.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clone',\n",
       " 'selu',\n",
       " 'top_k_categorical_accuracy',\n",
       " 'on_train_begin',\n",
       " '__init__',\n",
       " 'from_config',\n",
       " '__call__',\n",
       " '__init__',\n",
       " '__init__',\n",
       " 'he_uniform',\n",
       " 'logcosh',\n",
       " 'raise_duplicate_arg_error',\n",
       " '_get_available_devices',\n",
       " 'dl_progress',\n",
       " 'unpack_singleton',\n",
       " 'Xception',\n",
       " 'preprocess_input',\n",
       " 'decode_predictions',\n",
       " 'get_config',\n",
       " '__init__',\n",
       " '__init__',\n",
       " 'get_config',\n",
       " 'updates',\n",
       " 'cell',\n",
       " '_pooling_function',\n",
       " 'call',\n",
       " 'call',\n",
       " '__init__',\n",
       " '__init__',\n",
       " 'call',\n",
       " 'call',\n",
       " 'call',\n",
       " 'get_weights',\n",
       " 'get_losses_for',\n",
       " 'call',\n",
       " 'get_config',\n",
       " '__init__',\n",
       " 'is_keras_tensor',\n",
       " 'zeros',\n",
       " 'function',\n",
       " 'forward',\n",
       " 'int_shape',\n",
       " 'ndim',\n",
       " 'zeros_like',\n",
       " 'argmax',\n",
       " 'reshape',\n",
       " 'slice',\n",
       " 'in_test_phase',\n",
       " 'hard_sigmoid',\n",
       " 'foldl',\n",
       " '_prepare_name',\n",
       " 'is_keras_tensor',\n",
       " 'is_tensor',\n",
       " 'zeros',\n",
       " 'cumprod',\n",
       " 'argmax',\n",
       " 'clip',\n",
       " 'arange',\n",
       " 'elu',\n",
       " 'binary_crossentropy',\n",
       " '_preprocess_conv3d_input',\n",
       " 'random_binomial',\n",
       " 'map_fn',\n",
       " 'add_unprocessed_node',\n",
       " 'process_layer',\n",
       " 'convert_nested_time_distributed',\n",
       " 'transpose_input',\n",
       " '_node_key',\n",
       " 'updates',\n",
       " 'get_input_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " '_uses_dynamic_learning_phase',\n",
       " 'evaluate_generator']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clone'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_label_df.loc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] FunctionDef arguments arg y true arg y pred Expr Str FunctionDef arguments arg x Return BinOp BinOp Name Add Call Attribute softplus Name BinOp UnaryOp USub Num Mult Name Sub Call Attribute log Name Num Return Call Attribute mean Name Call Name BinOp Name Name keyword UnaryOp Num'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet = pd.read_csv(path+'sparse_fname_split_magret_tk_val.txt', header=None)\n",
    "snippet.loc[10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] FunctionDef arguments arg layer Return Call Attribute from config Attribute class Name Call Attribute get config Name\n",
      "Label = clone\n",
      "Pred  =\n",
      "     0. deserialize\n",
      "     1. unpickle_model\n",
      "     2. model_from_config\n",
      "     3. get_config\n",
      "     4. model_from_yaml\n",
      "     5. from_config\n",
      "     6. _pooling_function\n",
      "\n",
      "[CLS] FunctionDef arguments arg x Expr Str Assign Name alpha Num Assign Name scale Num Return BinOp Name Mult Call Attribute elu Name Name Name\n",
      "Label = selu\n",
      "Pred  =\n",
      "     0. __init__\n",
      "     1. set_params\n",
      "     2. pickle_model\n",
      "     3. clone_model\n",
      "     4. predict_proba\n",
      "     5. __setstate__\n",
      "     6. set_weights\n",
      "\n",
      "[CLS] FunctionDef arguments arg y true arg y pred arg k Num Return Call Attribute mean Name Call Attribute in top k Name Name Call Attribute argmax Name Name keyword UnaryOp USub Num Name keyword UnaryOp Num\n",
      "Label = top_k_categorical_accuracy\n",
      "Pred  =\n",
      "     0. on_train_begin\n",
      "     1. on_train_end\n",
      "     2. get_config\n",
      "     3. on_epoch_end\n",
      "     4. call\n",
      "     5. count_params\n",
      "     6. get\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg logs NameConstant Assign Attribute wait Name Num Assign Attribute stopped epoch Name Num If Compare Attribute baseline Name IsNot NameConstant Assign Attribute best Name Attribute baseline Name Assign Attribute best Name IfExp Compare Attribute monitor op Name Eq Attribute less Name Attribute Inf Name UnaryOp USub Attribute Inf Name\n",
      "Label = on_train_begin\n",
      "Pred  =\n",
      "     0. get_config\n",
      "     1. stop_gradient\n",
      "     2. __init__\n",
      "     3. call\n",
      "     4. is_sparse\n",
      "     5. _get_executor_init\n",
      "     6. gather\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg root arg path arg field arg headers arg send as json Str Str Str NameConstant NameConstant Expr Call Attribute init Call Name Name Name Assign Attribute root Name Name Assign Attribute path Name Name Assign Attribute field Name Name Assign Attribute headers Name Name Assign Attribute send as json Name Name\n",
      "Label = __init__\n",
      "Pred  =\n",
      "     0. from_config\n",
      "     1. decode_predictions\n",
      "     2. get_output_at\n",
      "     3. print_layer_summary\n",
      "     4. print_tensor\n",
      "     5. update\n",
      "     6. get_input_shape_at\n",
      "\n",
      "[CLS] FunctionDef arguments arg cls arg config If Compare Str In Name Expr Call Attribute pop Name Str Return Call Name keyword Name Name\n",
      "Label = from_config\n",
      "Pred  =\n",
      "     0. __init__\n",
      "     1. call\n",
      "     2. on_train_begin\n",
      "     3. constraints\n",
      "     4. update_add\n",
      "     5. in_top_k\n",
      "     6. get_config\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg shape arg dtype NameConstant Return Call Attribute constant Name Attribute value Name keyword Name keyword Name\n",
      "Label = __call__\n",
      "Pred  =\n",
      "---- 0. __call__\n",
      "     1. forward\n",
      "     2. call\n",
      "     3. random_normal\n",
      "     4. infer_outputs\n",
      "     5. count_params\n",
      "     6. get_losses_for\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg mean arg stddev arg seed Num Num NameConstant Assign Attribute mean Name Name Assign Attribute stddev Name Name Assign Attribute seed Name Name\n",
      "Label = __init__\n",
      "Pred  =\n",
      "     0. get_config\n",
      "---- 1. __init__\n",
      "     2. updates\n",
      "     3. count_params\n",
      "     4. model_from_yaml\n",
      "     5. compute_output_shape\n",
      "     6. get_tuple_shape\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg minval arg maxval arg seed UnaryOp USub Num Num NameConstant Assign Attribute minval Name Name Assign Attribute maxval Name Name Assign Attribute seed Name Name\n",
      "Label = __init__\n",
      "Pred  =\n",
      "     0. lecun_normal\n",
      "     1. he_normal\n",
      "     2. lecun_uniform\n",
      "     3. glorot_uniform\n",
      "     4. he_uniform\n",
      "     5. minimum\n",
      "     6. std\n",
      "\n",
      "[CLS] FunctionDef arguments arg seed NameConstant Expr Str Return Call Name keyword Num keyword Str keyword Str keyword Name\n",
      "Label = he_uniform\n",
      "Pred  =\n",
      "     0. call\n",
      "     1. __call__\n",
      "     2. compute_mask\n",
      "     3. step\n",
      "     4. get_weights\n",
      "     5. compute_output_shape\n",
      "     6. count_params\n",
      "\n",
      "[CLS] FunctionDef arguments arg y true arg y pred Expr Str FunctionDef arguments arg x Return BinOp BinOp Name Add Call Attribute softplus Name BinOp UnaryOp USub Num Mult Name Sub Call Attribute log Name Num Return Call Attribute mean Name Call Name BinOp Name Name keyword UnaryOp Num\n",
      "Label = logcosh\n",
      "Pred  =\n",
      "     0. __init__\n",
      "     1. __call__\n",
      "     2. preprocess_input\n",
      "     3. __contains__\n",
      "     4. h5wrapper\n",
      "     5. decode_predictions\n",
      "     6. add_unprocessed_node\n",
      "\n",
      "[CLS] FunctionDef arguments arg old arg arg new arg Raise Call Name BinOp BinOp BinOp BinOp BinOp BinOp Str Add Name Str Name Str Name Str\n",
      "Label = raise_duplicate_arg_error\n",
      "Pred  =\n",
      "     0. __init__\n",
      "     1. get\n",
      "     2. update_add\n",
      "     3. constraints\n",
      "     4. in_top_k\n",
      "     5. forward\n",
      "     6. mean\n",
      "\n",
      "[CLS] FunctionDef arguments Return ListComp Attribute name Name comprehension Name x Call Attribute list devices Call Attribute get session Name\n",
      "Label = _get_available_devices\n",
      "Pred  =\n",
      "     0. on_epoch_end\n",
      "     1. call\n",
      "     2. dl_progress\n",
      "     3. on_train_end\n",
      "     4. on_batch_begin\n",
      "     5. __init__\n",
      "     6. mean_absolute_percentage_error\n",
      "\n",
      "[CLS] FunctionDef arguments arg count arg block size arg total size If Compare Attribute progbar Name Is NameConstant If Compare Name UnaryOp USub Num Assign Name total size NameConstant Assign Attribute progbar Name Call Name Name Expr Call Attribute update Attribute progbar Name BinOp Name Mult Name\n",
      "Label = dl_progress\n",
      "Pred  =\n",
      "     0. get_word_index\n",
      "     1. deserialize\n",
      "     2. __init__\n",
      "     3. on_train_end\n",
      "     4. size\n",
      "     5. model_from_yaml\n",
      "     6. stateful\n",
      "\n",
      "[CLS] FunctionDef arguments arg x Expr Str If Compare Call Name Name Eq Num Return Subscript Name Index Num Return Name\n",
      "Label = unpack_singleton\n",
      "Pred  =\n",
      "     0. decode_predictions\n",
      "     1. preprocess_input\n",
      "     2. MobileNetV2\n",
      "     3. make_batches\n",
      "     4. InceptionV3\n",
      "     5. step\n",
      "     6. in_top_k\n",
      "\n",
      "[CLS] FunctionDef arguments arg args arg kwargs Return Call Attribute Xception Name Starred Name keyword Name Name\n",
      "Label = Xception\n",
      "Pred  =\n",
      "     0. preprocess_input\n",
      "     1. decode_predictions\n",
      "     2. DenseNet169\n",
      "     3. moving_average_update\n",
      "     4. get_losses_for\n",
      "     5. VGG19\n",
      "     6. MobileNetV2\n",
      "\n",
      "[CLS] FunctionDef arguments arg args arg kwargs Return Call Attribute preprocess input Name Starred Name keyword Name Name\n",
      "Label = preprocess_input\n",
      "Pred  =\n",
      "     0. __init__\n",
      "     1. get_config\n",
      "     2. constraints\n",
      "     3. update_add\n",
      "     4. get\n",
      "     5. mean\n",
      "     6. forward\n",
      "\n",
      "[CLS] FunctionDef arguments arg args arg kwargs Return Call Attribute decode predictions Name Starred Name keyword Name Name\n",
      "Label = decode_predictions\n",
      "Pred  =\n",
      "     0. _merge_function\n",
      "     1. get_uid\n",
      "     2. logsumexp\n",
      "     3. batch_set_value\n",
      "     4. __iter__\n",
      "     5. random_uniform_variable\n",
      "     6. get\n",
      "\n",
      "[CLS] FunctionDef arguments arg self Assign Name config Dict Str Attribute axis Name Assign Name base config Call Attribute get config Call Name Name Name Return Call Name BinOp Call Name Call Attribute items Name Add Call Name Call Attribute items Name\n",
      "Label = get_config\n",
      "Pred  =\n",
      "     0. call\n",
      "     1. compute_mask\n",
      "     2. __call__\n",
      "     3. step\n",
      "     4. get_weights\n",
      "     5. __init__\n",
      "     6. _collect_input_shape\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg alpha arg kwargs Num Expr Call Attribute init Call Name Name Name keyword Name Assign Attribute supports masking Name NameConstant Assign Attribute alpha Name Call Attribute cast to floatx Name Name\n",
      "Label = __init__\n",
      "Pred  =\n",
      "     0. maximum\n",
      "     1. minimum\n",
      "     2. average\n",
      "     3. l2_normalize\n",
      "     4. on_epoch_end\n",
      "     5. get_losses_for\n",
      "     6. step\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg axis arg kwargs UnaryOp USub Num Expr Call Attribute init Call Name Name Name keyword Name Assign Attribute supports masking Name NameConstant Assign Attribute axis Name Name\n",
      "Label = __init__\n",
      "Pred  =\n",
      "     0. maximum\n",
      "     1. minimum\n",
      "     2. average\n",
      "     3. l2_normalize\n",
      "     4. on_epoch_end\n",
      "     5. get_losses_for\n",
      "     6. step\n",
      "\n",
      "[CLS] FunctionDef arguments arg self Assign Name config Dict Str Str Str Attribute max value Name Attribute negative slope Name Attribute threshold Name Assign Name base config Call Attribute get config Call Name Name Name Return Call Name BinOp Call Name Call Attribute items Name Add Call Name Call Attribute items Name\n",
      "Label = get_config\n",
      "Pred  =\n",
      "     0. maximum\n",
      "     1. minimum\n",
      "     2. average\n",
      "     3. l2_normalize\n",
      "     4. on_epoch_end\n",
      "     5. get_losses_for\n",
      "     6. step\n",
      "\n",
      "[CLS] FunctionDef arguments arg self If Call Name Attribute forward layer Name Str Return BinOp Attribute updates Attribute forward layer Name Add Attribute updates Attribute backward layer Name Return List Name\n",
      "Label = updates\n",
      "Pred  =\n",
      "     0. minimum\n",
      "     1. maximum\n",
      "     2. average\n",
      "     3. concatenate\n",
      "     4. l2_normalize\n",
      "     5. function\n",
      "     6. _merge_function\n",
      "\n",
      "[CLS] FunctionDef arguments arg self Assign Name Cell Call Name Str Str Assign Name cell Call Name keyword Attribute units Name Return Name Name\n",
      "Label = cell\n",
      "Pred  =\n",
      "     0. call\n",
      "     1. __call__\n",
      "     2. compute_mask\n",
      "     3. step\n",
      "     4. get_losses_for\n",
      "     5. get_weights\n",
      "     6. elu\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg inputs arg pool size arg strides arg padding arg data format Assign Name output Call Attribute pool2d Name Name Name Name Name Name keyword Str Return Name\n",
      "Label = _pooling_function\n",
      "Pred  =\n",
      "     0. call\n",
      "     1. compute_mask\n",
      "     2. __call__\n",
      "     3. step\n",
      "     4. __init__\n",
      "     5. get_updates_for\n",
      "     6. _get_noise_shape\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg inputs Assign Name output Call Attribute pooling function Name keyword Name keyword Attribute pool size Name keyword Attribute strides Name keyword Attribute padding Name keyword Attribute data format Name Return Name\n",
      "Label = call\n",
      "Pred  =\n",
      "     0. __init__\n",
      "     1. get_config\n",
      "     2. constraints\n",
      "     3. update_add\n",
      "     4. mean\n",
      "---- 5. call\n",
      "     6. forward\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg inputs arg mask arg training arg initial state NameConstant NameConstant NameConstant Return Call Attribute call Call Name Name Name Name keyword Name keyword Name keyword Name\n",
      "Label = call\n",
      "Pred  =\n",
      "     0. compute_output_shape\n",
      "     1. ctc_step\n",
      "     2. not_equal\n",
      "     3. _get_noise_shape\n",
      "     4. build\n",
      "     5. print_layer_summary\n",
      "     6. cell\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg size arg data format arg kwargs NameConstant Assign Attribute rank Name Call Name Name Assign Attribute size Name Name Assign Attribute data format Name Call Attribute normalize data format Name Name Assign Attribute input spec Name Call Name keyword BinOp Attribute rank Name Add Num Expr Call Attribute init Call Name Name Name keyword Name\n",
      "Label = __init__\n",
      "Pred  =\n",
      "     0. trainable_weights\n",
      "     1. non_trainable_weights\n",
      "     2. weights\n",
      "     3. updates\n",
      "     4. get_weights\n",
      "     5. _check_trainable_weights_consistency\n",
      "     6. _get_dynamic_axis_num\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg size arg kwargs Num Expr Call Attribute init Call Name Name Name Tuple Call Name Name Str keyword Name Attribute legacy upsampling1d support Name\n",
      "Label = __init__\n",
      "Pred  =\n",
      "     0. updates\n",
      "     1. get_config\n",
      "     2. get_weights\n",
      "     3. non_trainable_weights\n",
      "     4. activity_regularizer\n",
      "     5. losses\n",
      "     6. count_params\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg inputs Assign Name output Call Attribute repeat elements Name Name Subscript Attribute size Name Index Num keyword Num Return Name\n",
      "Label = call\n",
      "Pred  =\n",
      "     0. get_config\n",
      "     1. __init__\n",
      "     2. count_params\n",
      "     3. model_from_yaml\n",
      "     4. updates\n",
      "     5. get\n",
      "     6. is_sparse\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg inputs Return Call Attribute spatial 2d padding Name Name keyword Attribute padding Name keyword Attribute data format Name\n",
      "Label = call\n",
      "Pred  =\n",
      "     0. __init__\n",
      "     1. get_config\n",
      "     2. _pooling_function\n",
      "     3. constraints\n",
      "---- 4. call\n",
      "     5. mean\n",
      "     6. update_add\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg inputs Assign Name output Call Attribute local conv1d Name Name Attribute kernel Name Attribute kernel size Name Attribute strides Name If Attribute use bias Name Assign Name output Call Attribute bias add Name Name Attribute bias Name If Compare Attribute activation Name IsNot NameConstant Assign Name output Call Attribute activation Name Name Return Name\n",
      "Label = call\n",
      "Pred  =\n",
      "     0. __init__\n",
      "---- 1. call\n",
      "     2. constraints\n",
      "     3. update_add\n",
      "     4. get_config\n",
      "     5. mean\n",
      "     6. _reshape_sequence\n",
      "\n",
      "[CLS] FunctionDef arguments arg self Expr Str Assign Name weights List For Name cell Attribute cells Name If Call Name Name Name AugAssign Name weights Add Attribute weights Name Return Call Attribute batch get value Name Name\n",
      "Label = get_weights\n",
      "Pred  =\n",
      "     0. step\n",
      "     1. call\n",
      "     2. get_losses_for\n",
      "     3. _get_noise_shape\n",
      "     4. flatten\n",
      "     5. decode_predictions\n",
      "     6. foldl\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg inputs NameConstant Assign Name losses List For Name cell Attribute cells Name If Call Name Name Name Assign Name cell losses Call Attribute get losses for Name Name AugAssign Name losses Add Name Return Name\n",
      "Label = get_losses_for\n",
      "Pred  =\n",
      "     0. get_config\n",
      "     1. __init__\n",
      "     2. updates\n",
      "     3. compute_output_shape\n",
      "     4. count_params\n",
      "     5. in_top_k\n",
      "     6. model_from_yaml\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg inputs arg training NameConstant If Compare Num Lt Attribute rate Name Num Assign Name noise shape Call Attribute get noise shape Name Name FunctionDef arguments Return Call Attribute dropout Name Name Attribute rate Name Name keyword Attribute seed Name Return Call Attribute in train phase Name Name Name keyword Name Return Name\n",
      "Label = call\n",
      "Pred  =\n",
      "---- 0. call\n",
      "     1. compute_mask\n",
      "     2. __init__\n",
      "     3. _pooling_function\n",
      "     4. get_updates_for\n",
      "     5. __call__\n",
      "     6. _collect_input_shape\n",
      "\n",
      "[CLS] FunctionDef arguments arg self Assign Name config Dict Str Call Attribute serialize Name Attribute activation Name Assign Name base config Call Attribute get config Call Name Name Name Return Call Name BinOp Call Name Call Attribute items Name Add Call Name Call Attribute items Name\n",
      "Label = get_config\n",
      "Pred  =\n",
      "---- 0. get_config\n",
      "     1. __init__\n",
      "     2. count_params\n",
      "     3. updates\n",
      "     4. model_from_yaml\n",
      "     5. get_tuple_shape\n",
      "     6. get\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg dims arg kwargs Expr Call Attribute init Call Name Name Name keyword Name Assign Attribute dims Name Call Name Name Assign Attribute input spec Name Call Name keyword BinOp Call Name Attribute dims Name Add Num\n",
      "Label = __init__\n",
      "Pred  =\n",
      "     0. compute_mask\n",
      "     1. call\n",
      "     2. step\n",
      "     3. function\n",
      "     4. NASNetMobile\n",
      "     5. build\n",
      "     6. get_weights\n",
      "\n",
      "[CLS] FunctionDef arguments arg x If UnaryOp Not Call Name Name Raise Call Name BinOp BinOp Str Add Call Name Call Name Name Str Return Call Name Name Str\n",
      "Label = is_keras_tensor\n",
      "Pred  =\n",
      "     0. from_config\n",
      "     1. decode_predictions\n",
      "     2. print_tensor\n",
      "     3. print_layer_summary\n",
      "     4. update\n",
      "     5. get_output_at\n",
      "     6. get_losses_for\n",
      "\n",
      "[CLS] FunctionDef arguments arg shape arg dtype arg name NameConstant NameConstant If Compare Name Is NameConstant Assign Name dtype Call Name Assign Name ctype Call Name Name Return Call Name keyword Call Attribute zeros Name Name Name keyword Name keyword Name\n",
      "Label = zeros\n",
      "Pred  =\n",
      "     0. losses\n",
      "     1. get_losses_for\n",
      "     2. __call__\n",
      "     3. binary_crossentropy\n",
      "     4. uses_learning_phase\n",
      "     5. classification_error\n",
      "     6. compute_output_shape\n",
      "\n",
      "[CLS] FunctionDef arguments arg inputs arg outputs arg updates arg kwargs List Return Call Name Name Name keyword Name keyword Name\n",
      "Label = function\n",
      "Pred  =\n",
      "     0. call\n",
      "     1. compute_mask\n",
      "     2. __init__\n",
      "     3. step\n",
      "     4. get_updates_for\n",
      "     5. all\n",
      "     6. _is_current_explicit_device\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg argument arg device arg outputs to retain NameConstant NameConstant If Call Attribute when Name Name Expr Call Attribute execute Name Name Return Tuple NameConstant Name\n",
      "Label = forward\n",
      "Pred  =\n",
      "     0. call\n",
      "     1. compute_mask\n",
      "     2. __init__\n",
      "     3. step\n",
      "     4. get_updates_for\n",
      "     5. all\n",
      "     6. _is_current_explicit_device\n",
      "\n",
      "[CLS] FunctionDef arguments arg x Expr Str If Call Name Name Str Return Attribute keras shape Name Try Return Call Name Call Attribute as list Call Attribute get shape Name ExceptHandler Name Return NameConstant\n",
      "Label = int_shape\n",
      "Pred  =\n",
      "     0. bias_initializer\n",
      "     1. infer_outputs\n",
      "     2. moving_average_update\n",
      "     3. process_layer\n",
      "     4. stack\n",
      "     5. mean\n",
      "     6. normalize_data_format\n",
      "\n",
      "[CLS] FunctionDef arguments arg x Expr Str Assign Name dims Attribute dims Call Attribute get shape Name If Compare Name IsNot NameConstant Return Call Name Name Return NameConstant\n",
      "Label = ndim\n",
      "Pred  =\n",
      "     0. noised\n",
      "     1. __call__\n",
      "     2. sqrt\n",
      "     3. __init__\n",
      "     4. _get_noise_shape\n",
      "     5. random_normal\n",
      "     6. _generate_dropout_mask\n",
      "\n",
      "[CLS] FunctionDef arguments arg x arg dtype arg name NameConstant NameConstant Expr Str Return Call Attribute zeros like Name Name keyword Name keyword Name\n",
      "Label = zeros_like\n",
      "Pred  =\n",
      "     0. __init__\n",
      "     1. constraints\n",
      "     2. update_add\n",
      "     3. in_top_k\n",
      "     4. mean\n",
      "     5. forward\n",
      "     6. get_config\n",
      "\n",
      "[CLS] FunctionDef arguments arg x arg axis UnaryOp USub Num Expr Str Return Call Attribute argmax Name Name Name\n",
      "Label = argmax\n",
      "Pred  =\n",
      "     0. __init__\n",
      "     1. call\n",
      "     2. compute_mask\n",
      "     3. constraints\n",
      "     4. update_add\n",
      "     5. in_top_k\n",
      "     6. get_config\n",
      "\n",
      "[CLS] FunctionDef arguments arg x arg shape Expr Str Return Call Attribute reshape Name Name Name\n",
      "Label = reshape\n",
      "Pred  =\n",
      "     0. compute_output_shape\n",
      "     1. build\n",
      "     2. cell\n",
      "     3. get_config\n",
      "     4. call\n",
      "     5. print_layer_summary\n",
      "     6. argmin\n",
      "\n",
      "[CLS] FunctionDef arguments arg x arg start arg size Expr Str Return Call Attribute slice Name Name Name Name\n",
      "Label = slice\n",
      "Pred  =\n",
      "     0. __call__\n",
      "     1. identity\n",
      "     2. stack\n",
      "     3. set_value\n",
      "     4. update\n",
      "     5. count_params\n",
      "     6. softsign\n",
      "\n",
      "[CLS] FunctionDef arguments arg x arg alt arg training NameConstant Expr Str Return Call Name Name Name keyword Name\n",
      "Label = in_test_phase\n",
      "Pred  =\n",
      "     0. _preprocess_padding\n",
      "     1. is_placeholder\n",
      "     2. _convert_string_dtype\n",
      "     3. _convert_dtype_string\n",
      "     4. serialize_keras_object\n",
      "     5. batch_get_value\n",
      "     6. _prepare_name\n",
      "\n",
      "[CLS] FunctionDef arguments arg x Expr Str Assign Name x BinOp BinOp Num Mult Name Add Num Assign Name zero Call Name Num Attribute base dtype Attribute dtype Name Assign Name one Call Name Num Attribute base dtype Attribute dtype Name Assign Name x Call Attribute clip by value Name Name Name Name Return Name\n",
      "Label = hard_sigmoid\n",
      "Pred  =\n",
      "     0. get_value\n",
      "     1. set_value\n",
      "     2. is_tensor\n",
      "     3. batch_get_value\n",
      "     4. stop_gradient\n",
      "     5. backward\n",
      "     6. sqrt\n",
      "\n",
      "[CLS] FunctionDef arguments arg fn arg elems arg initializer arg name NameConstant NameConstant Expr Str Return Call Attribute foldl Name Name Name keyword Name keyword Name\n",
      "Label = foldl\n",
      "Pred  =\n",
      "     0. reshape\n",
      "     1. count_params\n",
      "     2. _is_explicit_shape\n",
      "     3. cast\n",
      "     4. __init__\n",
      "     5. set_learning_phase\n",
      "     6. _reshape_sequence\n",
      "\n",
      "[CLS] FunctionDef arguments arg name arg default Assign Name prefix Call Attribute join Str Name If Compare Name Is NameConstant Return BinOp BinOp Name Add Str Name Return BinOp BinOp Name Str Name\n",
      "Label = _prepare_name\n",
      "Pred  =\n",
      "     0. gather\n",
      "     1. __init__\n",
      "     2. call\n",
      "     3. one_hot\n",
      "     4. in_top_k\n",
      "     5. _reshape_sequence\n",
      "     6. ctc_step\n",
      "\n",
      "[CLS] FunctionDef arguments arg x Expr Str If UnaryOp Not Call Name Name Raise Call Name BinOp BinOp Str Add Call Name Call Name Name Str Return Call Name Name Str\n",
      "Label = is_keras_tensor\n",
      "Pred  =\n",
      "     0. argmin\n",
      "     1. argmax\n",
      "     2. concatenate\n",
      "     3. expand_dims\n",
      "     4. any\n",
      "     5. softmax\n",
      "     6. l2_normalize\n",
      "\n",
      "[CLS] FunctionDef arguments arg x Return Call Name Name Tuple Attribute TensorVariable Name Attribute TensorSharedVariable Attribute sharedvar Name\n",
      "Label = is_tensor\n",
      "Pred  =\n",
      "     0. argmin\n",
      "     1. argmax\n",
      "     2. softmax\n",
      "     3. expand_dims\n",
      "     4. concatenate\n",
      "     5. cumsum\n",
      "     6. cumprod\n",
      "\n",
      "[CLS] FunctionDef arguments arg shape arg dtype arg name NameConstant NameConstant Expr Str If Compare Name Is NameConstant Assign Name dtype Call Name Return Call Name Call Attribute zeros Name Name Name Name\n",
      "Label = zeros\n",
      "Pred  =\n",
      "     0. __init__\n",
      "     1. get_config\n",
      "     2. call\n",
      "     3. in_top_k\n",
      "     4. on_train_begin\n",
      "     5. forward\n",
      "     6. constraints\n",
      "\n",
      "[CLS] FunctionDef arguments arg x arg axis Num Expr Str Return Call Attribute cumprod Attribute extra ops Name Name keyword Name\n",
      "Label = cumprod\n",
      "Pred  =\n",
      "     0. infer_outputs\n",
      "     1. __call__\n",
      "     2. call\n",
      "     3. elu\n",
      "     4. is_keras_tensor\n",
      "     5. random_uniform_variable\n",
      "     6. moving_average_update\n",
      "\n",
      "[CLS] FunctionDef arguments arg x arg axis UnaryOp USub Num Return Call Attribute argmax Name Name keyword Name keyword NameConstant\n",
      "Label = argmax\n",
      "Pred  =\n",
      "     0. validate_file\n",
      "     1. from_config\n",
      "     2. _uses_dynamic_learning_phase\n",
      "     3. sparse_top_k_categorical_accuracy\n",
      "     4. on_train_end\n",
      "     5. binary_accuracy\n",
      "     6. ask_to_proceed_with_overwrite\n",
      "\n",
      "[CLS] FunctionDef arguments arg x arg min value arg max value If BoolOp And Compare Name IsNot NameConstant Compare Name Lt Name Assign Name max value Name If Compare Name Is NameConstant Assign Name max value Attribute inf Name Return Call Attribute clip Name Name Name Name\n",
      "Label = clip\n",
      "Pred  =\n",
      "     0. zeros_like\n",
      "     1. ones_like\n",
      "     2. sqrt\n",
      "     3. to_dense\n",
      "     4. __call__\n",
      "     5. cast\n",
      "     6. set_value\n",
      "\n",
      "[CLS] FunctionDef arguments arg start arg stop arg step arg dtype NameConstant Num Str Expr Str Return Call Attribute arange Name Name keyword Name keyword Name keyword Name\n",
      "Label = arange\n",
      "Pred  =\n",
      "     0. eval\n",
      "     1. step\n",
      "     2. maximum\n",
      "     3. ones_like\n",
      "     4. _assert_has_capability\n",
      "     5. is_keras_tensor\n",
      "     6. get_variable_shape\n",
      "\n",
      "[CLS] FunctionDef arguments arg x arg alpha Num Expr Str Expr Call Name Attribute nnet Name Str Return Call Attribute elu Attribute nnet Name Name Name\n",
      "Label = elu\n",
      "Pred  =\n",
      "     0. max\n",
      "     1. prod\n",
      "     2. min\n",
      "     3. logsumexp\n",
      "     4. sum\n",
      "     5. mean\n",
      "     6. std\n",
      "\n",
      "[CLS] FunctionDef arguments arg target arg output arg from logits NameConstant If Name Assign Name output Call Attribute sigmoid Attribute nnet Name Name Assign Name output Call Attribute clip Name Name Call Name BinOp Num Sub Call Name Return Call Attribute binary crossentropy Attribute nnet Name Name Name\n",
      "Label = binary_crossentropy\n",
      "Pred  =\n",
      "     0. flatten\n",
      "     1. is_all_none\n",
      "     2. argmin\n",
      "     3. _canonical_to_params\n",
      "     4. argmax\n",
      "     5. reverse\n",
      "     6. iter_sequence_infinite\n",
      "\n",
      "[CLS] FunctionDef arguments arg x arg data format If Compare Name Eq Str Assign Name x Call Attribute dimshuffle Name Tuple Num Num Num Num Num Return Name\n",
      "Label = _preprocess_conv3d_input\n",
      "Pred  =\n",
      "     0. stack\n",
      "     1. repeat\n",
      "     2. reverse\n",
      "     3. _reshape_batch\n",
      "     4. concatenate\n",
      "     5. argmin\n",
      "     6. _normalize_device_name\n",
      "\n",
      "[CLS] FunctionDef arguments arg shape arg p arg dtype arg seed Num NameConstant NameConstant If Compare Name Is NameConstant Assign Name dtype Call Name If Compare Name NameConstant Assign Name seed Call Attribute randint Attribute random Name Num Num Assign Name rng Call Name keyword Name Return Call Attribute binomial Name Name keyword Name keyword Name\n",
      "Label = random_binomial\n",
      "Pred  =\n",
      "     0. eval\n",
      "     1. ones_like\n",
      "     2. get_value\n",
      "     3. count_params\n",
      "     4. batch_get_value\n",
      "     5. in_test_phase\n",
      "     6. identity\n",
      "\n",
      "[CLS] FunctionDef arguments arg fn arg elems arg name arg dtype NameConstant NameConstant Expr Str Return Subscript Call Attribute map Name Name Name keyword Name Index Num\n",
      "Label = map_fn\n",
      "Pred  =\n",
      "     0. softsign\n",
      "     1. tanh\n",
      "     2. gather\n",
      "     3. softplus\n",
      "     4. cumsum\n",
      "     5. call\n",
      "     6. _regular_normalize_batch_in_training\n",
      "\n",
      "[CLS] FunctionDef arguments arg layer arg node data If Compare Name NotIn Name Assign Subscript Name Index Name List Name Expr Call Attribute append Subscript Name Index Name Name\n",
      "Label = add_unprocessed_node\n",
      "Pred  =\n",
      "     0. is_placeholder\n",
      "     1. int_shape\n",
      "     2. update\n",
      "     3. cumsum\n",
      "     4. InceptionV3\n",
      "     5. from_config\n",
      "     6. output_mask\n",
      "\n",
      "[CLS] FunctionDef arguments arg layer data Expr Str Assign Name layer name Subscript Name Index Str ImportFrom alias Assign Name layer Call Name Name keyword Name Assign Subscript Name Index Name Name Assign Name inbound nodes data Subscript Name Index Str For Name node data Name Expr Call Name Name Name\n",
      "Label = process_layer\n",
      "Pred  =\n",
      "     0. zeros\n",
      "     1. ones\n",
      "     2. eye\n",
      "     3. ones_like\n",
      "     4. constant\n",
      "     5. cell\n",
      "     6. __init__\n",
      "\n",
      "[CLS] FunctionDef arguments arg weights Expr Str Return Call Name Attribute layer Name Name Name Name\n",
      "Label = convert_nested_time_distributed\n",
      "Pred  =\n",
      "     0. ones_like\n",
      "     1. identity\n",
      "     2. zeros_like\n",
      "     3. foldl\n",
      "     4. map_fn\n",
      "     5. ndim\n",
      "     6. get_variable_shape\n",
      "\n",
      "[CLS] FunctionDef arguments arg from cudnn Expr Str Assign Name order IfExp Name Str Str FunctionDef arguments arg kernel Return Call Attribute reshape Attribute T Name Attribute shape Name keyword Name Return Name\n",
      "Label = transpose_input\n",
      "Pred  =\n",
      "     0. update_sub\n",
      "     1. update_add\n",
      "     2. decode_predictions\n",
      "     3. mean_absolute_error\n",
      "     4. int_shape\n",
      "     5. in_test_phase\n",
      "     6. softsign\n",
      "\n",
      "[CLS] FunctionDef arguments arg layer arg node index Expr Str Return BinOp BinOp Attribute name Name Add Str Call Name Name Name\n",
      "Label = _node_key\n",
      "Pred  =\n",
      "     0. logsumexp\n",
      "     1. prod\n",
      "     2. max\n",
      "     3. std\n",
      "     4. sum\n",
      "     5. min\n",
      "     6. mean\n",
      "\n",
      "[CLS] FunctionDef arguments arg self If BoolOp And UnaryOp Not Attribute trainable Name UnaryOp Attribute stateful Name Return List Return Attribute updates Name Name\n",
      "Label = updates\n",
      "Pred  =\n",
      "     0. random_uniform\n",
      "     1. map_fn\n",
      "     2. __call__\n",
      "     3. relu\n",
      "     4. call\n",
      "     5. lecun_normal\n",
      "     6. cumprod\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg node index Expr Str Return Call Attribute get node attribute at index Name Name Str Str\n",
      "Label = get_input_at\n",
      "Pred  =\n",
      "     0. predict_proba\n",
      "     1. _is_current_explicit_device\n",
      "     2. is_sparse\n",
      "     3. compute_mask\n",
      "     4. categorical_hinge\n",
      "     5. logsumexp\n",
      "     6. sparse_categorical_accuracy\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg node index Expr Str Return Call Attribute get node attribute at index Name Name Str Str\n",
      "Label = get_output_mask_at\n",
      "Pred  =\n",
      "     0. foldl\n",
      "     1. foldr\n",
      "     2. map_fn\n",
      "     3. identity\n",
      "     4. _is_explicit_shape\n",
      "     5. predict_proba\n",
      "     6. average\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg inputs If BoolOp And UnaryOp Not Attribute trainable Name UnaryOp Attribute stateful Name Return List If Compare Name IsNot NameConstant Assign Name inputs hash Call Name Name Assign Name inputs hash NameConstant If Compare Name In Attribute per input updates Name Return Subscript Attribute per input updates Name Index Name Return List\n",
      "Label = get_updates_for\n",
      "Pred  =\n",
      "     0. dropout\n",
      "     1. mean\n",
      "     2. __init__\n",
      "     3. forward\n",
      "     4. gradients\n",
      "     5. is_tensor\n",
      "     6. stop_gradient\n",
      "\n",
      "[CLS] FunctionDef arguments arg self Expr Str Assign Name params Attribute weights Name Return Call Attribute batch get value Name Name\n",
      "Label = get_weights\n",
      "Pred  =\n",
      "     0. predict_proba\n",
      "     1. predict_generator\n",
      "     2. dropout\n",
      "     3. score\n",
      "     4. predict\n",
      "     5. stack\n",
      "     6. normalize\n",
      "\n",
      "[CLS] FunctionDef arguments arg self Return BoolOp And Attribute uses learning phase Name UnaryOp Not Call Name Call Attribute learning phase Name Name\n",
      "Label = _uses_dynamic_learning_phase\n",
      "Pred  =\n",
      "     0. model_from_yaml\n",
      "     1. get\n",
      "     2. get_config\n",
      "     3. model_from_config\n",
      "     4. all\n",
      "     5. _get_current_tf_device\n",
      "     6. any\n",
      "\n",
      "[CLS] FunctionDef arguments arg self arg generator arg steps arg max queue size arg workers arg use multiprocessing arg verbose NameConstant Num Num NameConstant Num Expr Str Return Call Attribute evaluate generator Name Name Name keyword Name keyword Name keyword Name keyword Name keyword Name Attribute legacy generator methods support Name\n",
      "Label = evaluate_generator\n",
      "Pred  =\n",
      "     0. _make_node_key\n",
      "     1. from_config\n",
      "     2. get_config\n",
      "     3. compute_output_shape\n",
      "     4. get_input_mask_at\n",
      "     5. updates\n",
      "     6. get_output_shape_at\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_str = []; score = 0; rank =[]\n",
    "for idx, r in enumerate(preds):\n",
    "    print(snippet.loc[idx][0])\n",
    "    print(\"Label =\", labels_str[idx])\n",
    "    preds_ = []\n",
    "    print(\"Pred  =\")\n",
    "    correct = False\n",
    "    for i in range(7):\n",
    "        p = vocab_label_df.loc[r[i]][0] \n",
    "        if p==labels_str[idx]:\n",
    "            score +=1\n",
    "            rank.append(i+1)\n",
    "            print(\"---- {}. {}\".format(i,p))\n",
    "            correct = True\n",
    "        else:\n",
    "            print(\"     {}. {}\".format(i,p))\n",
    "        preds_.append(p)\n",
    "    if correct == False:\n",
    "        rank.append(i)\n",
    "    pred_str.append(preds_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09333333333333334"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9740259740259741"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.mean(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = io.mmread('../sparse/adj/0_sparse_fname2_split_magret_adj.mtx').toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fac2bc24ba8>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(m[56,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = np.eye(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_idx = np.random.permutation(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_matrix(m)\n",
    "shuffled_adj = nx.adjacency_matrix(G, nodelist=shuffle_idx).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(shuffled_adj)\n",
    "plt.xticks(range(20), idx);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye[:len(shuffled_adj), :len(shuffled_adj)] = shuffled_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fac2adf5b38>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
