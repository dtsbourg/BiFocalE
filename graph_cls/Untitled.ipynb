{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from scipy import sparse, io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_graphfile(datadir, dataname, max_nodes=None):\n",
    "    ''' Read data from https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets\n",
    "        graph index starts with 1 in file\n",
    "    Returns:\n",
    "        List of networkx objects with graph and node labels\n",
    "    '''\n",
    "    prefix = os.path.join(datadir, dataname, dataname)\n",
    "    filename_graph_indic = prefix + '_graph_indicator.txt'\n",
    "    # index of graphs that a given node belongs to\n",
    "    graph_indic={}\n",
    "    with open(filename_graph_indic) as f:\n",
    "        i=1\n",
    "        for line in f:\n",
    "            line=line.strip(\"\\n\")\n",
    "            graph_indic[i]=int(line)\n",
    "            i+=1\n",
    "\n",
    "    filename_nodes=prefix + '_node_labels.txt'\n",
    "    node_labels=[]\n",
    "    min_label_val = None\n",
    "    try:\n",
    "        with open(filename_nodes) as f:\n",
    "            has_zero = False\n",
    "            for line in f:\n",
    "                line=line.strip(\"\\n\")\n",
    "                l = int(line)\n",
    "                node_labels+=[l]\n",
    "                if min_label_val is None or min_label_val > l:\n",
    "                    min_label_val = l\n",
    "        # assume that node labels are consecutive\n",
    "        num_unique_node_labels = max(node_labels) - min_label_val + 1\n",
    "        node_labels = [l - min_label_val for l in node_labels]\n",
    "    except IOError:\n",
    "        print('No node labels')\n",
    " \n",
    "    filename_node_attrs=prefix + '_node_attributes.txt'\n",
    "    node_attrs=[]\n",
    "    try:\n",
    "        with open(filename_node_attrs) as f:\n",
    "            for line in f:\n",
    "                line = line.strip(\"\\s\\n\")\n",
    "                attrs = [float(attr) for attr in re.split(\"[,\\s]+\", line) if not attr == '']\n",
    "                node_attrs.append(np.array(attrs))\n",
    "    except IOError:\n",
    "        print('No node attributes')\n",
    "       \n",
    "    label_has_zero = False\n",
    "    filename_graphs=prefix + '_graph_labels.txt'\n",
    "    graph_labels=[]\n",
    "\n",
    "    label_vals = []\n",
    "    with open(filename_graphs) as f:\n",
    "        for line in f:\n",
    "            line=line.strip(\"\\n\")\n",
    "            val = int(line)\n",
    "            if val not in label_vals:\n",
    "                label_vals.append(val)\n",
    "            graph_labels.append(val)\n",
    "\n",
    "    label_map_to_int = {val:i for i, val in enumerate(label_vals)}\n",
    "    graph_labels = np.array([label_map_to_int[l] for l in graph_labels])\n",
    "    \n",
    "    filename_adj=prefix + '_A.txt'\n",
    "    adj_list={i:[] for i in range(1,len(graph_labels)+1)}    \n",
    "    index_graph={i:[] for i in range(1,len(graph_labels)+1)}\n",
    "    num_edges = 0\n",
    "    with open(filename_adj) as f:\n",
    "        for line in f:\n",
    "            line=line.strip(\"\\n\").split(\",\")\n",
    "            e0,e1=(int(line[0].strip(\" \")),int(line[1].strip(\" \")))\n",
    "            adj_list[graph_indic[e0]].append((e0,e1))\n",
    "            index_graph[graph_indic[e0]]+=[e0,e1]\n",
    "            num_edges += 1\n",
    "    for k in index_graph.keys():\n",
    "        index_graph[k]=[u-1 for u in set(index_graph[k])]\n",
    "\n",
    "    graphs=[]\n",
    "    for i in range(1,1+len(adj_list)):\n",
    "        # indexed from 1 here\n",
    "        G=nx.from_edgelist(adj_list[i])\n",
    "        if max_nodes is not None and G.number_of_nodes() > max_nodes:\n",
    "            continue\n",
    "      \n",
    "        # add features and labels\n",
    "        G.graph['label'] = graph_labels[i-1]\n",
    "        for u in G.nodes():\n",
    "            if len(node_labels) > 0:\n",
    "                #node_label_one_hot = [0] * num_unique_node_labels\n",
    "                node_label = node_labels[u-1]\n",
    "                #node_label_one_hot[node_label] = 1\n",
    "                G.node[u]['label'] = node_label\n",
    "            if len(node_attrs) > 0:\n",
    "                G.node[u]['feat'] = node_attrs[u-1]\n",
    "        if len(node_attrs) > 0:\n",
    "            G.graph['feat_dim'] = node_attrs[0].shape[0]\n",
    "\n",
    "        # relabeling\n",
    "        mapping={}\n",
    "        it=0\n",
    "        if float(nx.__version__)<2.0:\n",
    "            for n in G.nodes():\n",
    "                mapping[n]=it\n",
    "                it+=1\n",
    "        else:\n",
    "            for n in G.nodes:\n",
    "                mapping[n]=it\n",
    "                it+=1\n",
    "            \n",
    "        # indexed from 0\n",
    "        graphs.append(nx.relabel_nodes(G, mapping))\n",
    "    return graphs, num_unique_node_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No node attributes\n"
     ]
    }
   ],
   "source": [
    "datadir = \"\"\n",
    "dataname = \"Tox21_AHR\"\n",
    "Gs, nb_unique_node_labels = read_graphfile(datadir, dataname, max_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gs = [G for G in Gs if len(G.nodes) < 64]\n",
    "Gs = [G for G in Gs if len(G.nodes) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7807"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeDataView({0: {'label': 1}, 1: {'label': 0}, 2: {'label': 1}, 3: {'label': 2}, 4: {'label': 4}, 5: {'label': 1}, 6: {'label': 1}, 7: {'label': 1}, 8: {'label': 1}, 9: {'label': 1}, 10: {'label': 1}, 11: {'label': 1}, 12: {'label': 6}})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gs[392].nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.asarray([len(G.nodes) for G in Gs]) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_unique_node_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_0, count_1 = 0,0\n",
    "for G in Gs:\n",
    "    if G.graph['label'] == 0:\n",
    "        count_0 += 1\n",
    "    else:\n",
    "        count_1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6865, 942)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0,count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = range(len(Gs))\n",
    "shuffled = np.random.permutation(idx)\n",
    "pivot = int(len(Gs)*0.2)\n",
    "test_idx = shuffled[:pivot]\n",
    "train_idx = shuffled[pivot:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "train_labels, test_labels = [],[]\n",
    "for idx,G in enumerate(Gs):\n",
    "    l = G.graph['label']\n",
    "    if idx in train_idx:\n",
    "        train_labels.append(l)\n",
    "    else:\n",
    "        test_labels.append(l)\n",
    "    \n",
    "with open(os.path.join(datadir, dataname+'_label.txt'), 'w') as f:\n",
    "    for l in train_labels:\n",
    "        f.write(str(l)+'\\n')\n",
    "\n",
    "with open(os.path.join(datadir, dataname+'_label_val.txt'), 'w') as f:\n",
    "    for l in test_labels:\n",
    "        f.write(str(l)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TK\n",
    "train_tk, test_tk = [],[]\n",
    "for idx,G in enumerate(Gs):\n",
    "    l = [n[1]['label'] for n in G.nodes(data=True)]\n",
    "    if idx in train_idx:\n",
    "        train_tk.append(l)\n",
    "    else:\n",
    "        test_tk.append(l)\n",
    "\n",
    "with open(os.path.join(datadir, dataname+'_tk.txt'), 'w') as f:\n",
    "    w = csv.writer(f, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for tk in train_tk:\n",
    "        w.writerow(tk)\n",
    "    \n",
    "\n",
    "with open(os.path.join(datadir, dataname+'_tk_val.txt'), 'w') as f:\n",
    "    w = csv.writer(f, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for tk in test_tk:\n",
    "        w.writerow(tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeDataView({0: {'label': 1}, 1: {'label': 0}, 2: {'label': 1}, 3: {'label': 2}, 4: {'label': 4}, 5: {'label': 1}, 6: {'label': 1}, 7: {'label': 1}, 8: {'label': 1}, 9: {'label': 1}, 10: {'label': 1}, 11: {'label': 1}, 12: {'label': 6}})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gs[392].nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count, test_count = 0,0\n",
    "for idx,G in enumerate(Gs):\n",
    "    if idx in train_idx:\n",
    "        fname = str(train_count)+'_'+dataname+\"_adj\"+suffix+\".mtx\"\n",
    "    else:\n",
    "        fname = str(test_count)+'_'+dataname+\"_adj\"+suffix+\".mtx\"\n",
    "        \n",
    "    G_u = G.to_undirected()\n",
    "    adj = nx.adj_matrix(G_u).todense()\n",
    "    final = np.zeros((max_len,max_len), dtype=int)\n",
    "    final[1:adj.shape[0]+1, 1:adj.shape[1]+1] = adj\n",
    "    final += np.eye(max_len, dtype=int)\n",
    "    final[:,0] = np.ones(max_len)\n",
    "    final[0,:] = np.ones(max_len)\n",
    "\n",
    "    m = sparse.csr_matrix(final)\n",
    "    sparsedir = os.path.join(datadir, 'adj')\n",
    "    if not os.path.exists(sparsedir):\n",
    "        os.makedirs(sparsedir)\n",
    "    io.mmwrite(os.path.join(sparsedir, fname), m)\n",
    "    \n",
    "    if idx in train_idx:\n",
    "        train_count+= 1\n",
    "    else:\n",
    "        test_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count,len(train_idx), test_count,len(test_idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
