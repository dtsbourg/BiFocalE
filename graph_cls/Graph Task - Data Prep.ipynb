{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from scipy import sparse, io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_graphfile(datadir, dataname, max_nodes=None):\n",
    "    ''' Read data from https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets\n",
    "        graph index starts with 1 in file\n",
    "    Returns:\n",
    "        List of networkx objects with graph and node labels\n",
    "    '''\n",
    "    prefix = os.path.join(datadir, dataname, dataname)\n",
    "    filename_graph_indic = prefix + '_graph_indicator.txt'\n",
    "    # index of graphs that a given node belongs to\n",
    "    graph_indic={}\n",
    "    with open(filename_graph_indic) as f:\n",
    "        i=1\n",
    "        for line in f:\n",
    "            line=line.strip(\"\\n\")\n",
    "            graph_indic[i]=int(line)\n",
    "            i+=1\n",
    "\n",
    "    filename_nodes=prefix + '_node_labels.txt'\n",
    "    node_labels=[]\n",
    "    min_label_val = None\n",
    "    try:\n",
    "        with open(filename_nodes) as f:\n",
    "            has_zero = False\n",
    "            for line in f:\n",
    "                line=line.strip(\"\\n\")\n",
    "                l = int(line)\n",
    "                node_labels+=[l]\n",
    "                if min_label_val is None or min_label_val > l:\n",
    "                    min_label_val = l\n",
    "        # assume that node labels are consecutive\n",
    "        num_unique_node_labels = max(node_labels) - min_label_val + 1\n",
    "        node_labels = [l - min_label_val for l in node_labels]\n",
    "    except IOError:\n",
    "        print('No node labels')\n",
    " \n",
    "    filename_node_attrs=prefix + '_node_attributes.txt'\n",
    "    node_attrs=[]\n",
    "    try:\n",
    "        with open(filename_node_attrs) as f:\n",
    "            for line in f:\n",
    "                line = line.strip(\"\\s\\n\")\n",
    "                attrs = [float(attr) for attr in re.split(\"[,\\s]+\", line) if not attr == '']\n",
    "                node_attrs.append(np.array(attrs))\n",
    "    except IOError:\n",
    "        print('No node attributes')\n",
    "       \n",
    "    label_has_zero = False\n",
    "    filename_graphs=prefix + '_graph_labels.txt'\n",
    "    graph_labels=[]\n",
    "\n",
    "    label_vals = []\n",
    "    with open(filename_graphs) as f:\n",
    "        for line in f:\n",
    "            line=line.strip(\"\\n\")\n",
    "            val = int(line)\n",
    "            if val not in label_vals:\n",
    "                label_vals.append(val)\n",
    "            graph_labels.append(val)\n",
    "\n",
    "    label_map_to_int = {val:i for i, val in enumerate(label_vals)}\n",
    "    graph_labels = np.array([label_map_to_int[l] for l in graph_labels])\n",
    "    \n",
    "    filename_adj=prefix + '_A.txt'\n",
    "    adj_list={i:[] for i in range(1,len(graph_labels)+1)}    \n",
    "    index_graph={i:[] for i in range(1,len(graph_labels)+1)}\n",
    "    num_edges = 0\n",
    "    with open(filename_adj) as f:\n",
    "        for line in f:\n",
    "            line=line.strip(\"\\n\").split(\",\")\n",
    "            e0,e1=(int(line[0].strip(\" \")),int(line[1].strip(\" \")))\n",
    "            adj_list[graph_indic[e0]].append((e0,e1))\n",
    "            index_graph[graph_indic[e0]]+=[e0,e1]\n",
    "            num_edges += 1\n",
    "    for k in index_graph.keys():\n",
    "        index_graph[k]=[u-1 for u in set(index_graph[k])]\n",
    "\n",
    "    graphs=[]\n",
    "    for i in range(1,1+len(adj_list)):\n",
    "        # indexed from 1 here\n",
    "        G=nx.from_edgelist(adj_list[i])\n",
    "        if max_nodes is not None and G.number_of_nodes() > max_nodes:\n",
    "            continue\n",
    "      \n",
    "        # add features and labels\n",
    "        G.graph['label'] = graph_labels[i-1]\n",
    "        for u in G.nodes():\n",
    "            if len(node_labels) > 0:\n",
    "                #node_label_one_hot = [0] * num_unique_node_labels\n",
    "                node_label = node_labels[u-1]\n",
    "                #node_label_one_hot[node_label] = 1\n",
    "                G.node[u]['label'] = node_label\n",
    "            if len(node_attrs) > 0:\n",
    "                G.node[u]['feat'] = node_attrs[u-1]\n",
    "        if len(node_attrs) > 0:\n",
    "            G.graph['feat_dim'] = node_attrs[0].shape[0]\n",
    "\n",
    "        # relabeling\n",
    "        mapping={}\n",
    "        it=0\n",
    "        if float(nx.__version__)<2.0:\n",
    "            for n in G.nodes():\n",
    "                mapping[n]=it\n",
    "                it+=1\n",
    "        else:\n",
    "            for n in G.nodes:\n",
    "                mapping[n]=it\n",
    "                it+=1\n",
    "            \n",
    "        # indexed from 0\n",
    "        graphs.append(nx.relabel_nodes(G, mapping))\n",
    "    return graphs, num_unique_node_labels\n",
    "    #return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No node attributes\n"
     ]
    }
   ],
   "source": [
    "datadir = \"\"\n",
    "dataname = \"MSRC_9\"\n",
    "Gs, nb_unique_node_labels = read_graphfile(datadir, dataname, max_nodes=None)\n",
    "#Gs = read_graphfile(datadir, dataname, max_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gs = [G for G in Gs if len(G.nodes) < 128]\n",
    "Gs = [G for G in Gs if len(G.nodes) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(NodeDataView({0: {'label': 2}, 1: {'label': 2}, 2: {'label': 2}, 3: {'label': 2}, 4: {'label': 2}, 5: {'label': 2}, 6: {'label': 2}, 7: {'label': 2}, 8: {'label': 2}, 9: {'label': 2}, 10: {'label': 2}, 11: {'label': 2}, 12: {'label': 2}, 13: {'label': 2}, 14: {'label': 4}, 15: {'label': 2}, 16: {'label': 2}, 17: {'label': 2}, 18: {'label': 4}, 19: {'label': 2}, 20: {'label': 2}, 21: {'label': 2}, 22: {'label': 2}, 23: {'label': 2}, 24: {'label': 4}, 25: {'label': 2}, 26: {'label': 2}, 27: {'label': 2}, 28: {'label': 2}, 29: {'label': 2}, 30: {'label': 2}, 31: {'label': 2}, 32: {'label': 2}, 33: {'label': 2}, 34: {'label': 2}, 35: {'label': 2}, 36: {'label': 2}, 37: {'label': 2}, 38: {'label': 2}, 39: {'label': 2}, 40: {'label': 2}, 41: {'label': 2}, 42: {'label': 2}, 43: {'label': 2}, 44: {'label': 2}, 45: {'label': 2}, 46: {'label': 2}}),\n",
       " EdgeView([(0, 3), (0, 5), (1, 9), (1, 2), (1, 4), (1, 6), (2, 3), (2, 5), (2, 6), (2, 7), (2, 12), (2, 14), (3, 5), (4, 9), (5, 7), (5, 10), (5, 11), (6, 8), (6, 9), (6, 12), (6, 14), (7, 10), (7, 12), (7, 13), (8, 9), (8, 14), (9, 14), (9, 15), (10, 16), (10, 19), (10, 11), (10, 12), (10, 13), (11, 16), (12, 19), (12, 13), (12, 14), (13, 19), (14, 17), (14, 19), (14, 18), (14, 15), (15, 18), (15, 21), (16, 19), (16, 20), (17, 24), (17, 18), (17, 19), (17, 22), (18, 24), (18, 21), (19, 20), (19, 22), (19, 23), (20, 25), (20, 30), (20, 23), (21, 24), (21, 26), (22, 32), (22, 23), (22, 24), (22, 31), (23, 30), (23, 31), (24, 32), (24, 35), (24, 33), (24, 26), (24, 27), (24, 28), (25, 29), (25, 30), (26, 33), (26, 27), (27, 33), (28, 32), (28, 35), (29, 34), (29, 30), (30, 34), (30, 37), (30, 31), (31, 32), (31, 37), (32, 35), (32, 37), (32, 39), (33, 35), (33, 38), (34, 40), (34, 36), (34, 37), (35, 38), (35, 39), (35, 41), (35, 46), (35, 44), (36, 40), (36, 37), (37, 39), (37, 40), (38, 42), (38, 43), (38, 41), (39, 40), (39, 44), (40, 44), (40, 45), (41, 42), (41, 46), (42, 43), (42, 46), (44, 45), (44, 46)]),\n",
       " 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gs[0].nodes(data=True), Gs[0].edges, Gs[0].graph['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.asarray([len(G.nodes) for G in Gs]) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_unique_node_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {}\n",
    "for G in Gs:\n",
    "    if c.get(G.graph['label'], None) == None:\n",
    "        c[G.graph['label']] = 1\n",
    "    else:\n",
    "        c[G.graph['label']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 23, 1: 30, 2: 30, 3: 29, 4: 30, 5: 30, 6: 19, 7: 30}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = range(len(Gs))\n",
    "shuffled = np.random.permutation(idx)\n",
    "pivot = int(len(Gs)*0.2)\n",
    "test_idx = shuffled[:pivot]\n",
    "train_idx = shuffled[pivot:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "train_labels, test_labels = [],[]\n",
    "for idx,G in enumerate(Gs):\n",
    "    l = G.graph['label']\n",
    "    if idx in train_idx:\n",
    "        train_labels.append(l)\n",
    "    else:\n",
    "        test_labels.append(l)\n",
    "    \n",
    "with open(os.path.join(datadir, dataname+'_label.txt'), 'w') as f:\n",
    "    for l in train_labels:\n",
    "        f.write(str(l)+'\\n')\n",
    "\n",
    "with open(os.path.join(datadir, dataname+'_label_val.txt'), 'w') as f:\n",
    "    for l in test_labels:\n",
    "        f.write(str(l)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TK\n",
    "node_labels = True\n",
    "train_tk, test_tk = [],[]\n",
    "node_vocab = []\n",
    "for idx,G in enumerate(Gs):\n",
    "    if node_labels:\n",
    "        l = [n[1]['label'] for n in G.nodes(data=True)]\n",
    "    else:\n",
    "        l = [int(n[1]['feat'][0]) for n in G.nodes(data=True)]\n",
    "        #l = [1 for _ in G.nodes]\n",
    "    for w in l:\n",
    "        if w not in node_vocab:\n",
    "            node_vocab.append(w)\n",
    "    l.insert(0,'[CLS]')\n",
    "    if idx in train_idx:\n",
    "        train_tk.append(l)\n",
    "    else:\n",
    "        test_tk.append(l)\n",
    "\n",
    "with open(os.path.join(datadir, dataname+'_tk.txt'), 'w') as f:\n",
    "    w = csv.writer(f, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for tk in train_tk:\n",
    "        w.writerow(tk)\n",
    "        w.writerow([])\n",
    "    \n",
    "\n",
    "with open(os.path.join(datadir, dataname+'_tk_val.txt'), 'w') as f:\n",
    "    w = csv.writer(f, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for tk in test_tk:\n",
    "        w.writerow(tk)\n",
    "        w.writerow([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count, test_count = 0,0\n",
    "for idx,G in enumerate(Gs):\n",
    "    if idx in train_idx:\n",
    "        fname = str(train_count)+'_'+dataname+\"_adj.mtx\"\n",
    "    else:\n",
    "        fname = str(test_count)+'_'+dataname+\"_adj_val.mtx\"\n",
    "        \n",
    "    G_u = G.to_undirected()\n",
    "    adj = nx.adj_matrix(G_u).todense()\n",
    "    final = np.zeros((max_len,max_len), dtype=int)\n",
    "    final[1:adj.shape[0]+1, 1:adj.shape[1]+1] = adj\n",
    "    final += np.eye(max_len, dtype=int)\n",
    "    final[:,0] = np.ones(max_len)\n",
    "    final[0,:] = np.ones(max_len)\n",
    "\n",
    "    m = sparse.csr_matrix(final)\n",
    "    sparsedir = os.path.join(datadir, 'adj')\n",
    "    if not os.path.exists(sparsedir):\n",
    "        os.makedirs(sparsedir)\n",
    "    io.mmwrite(os.path.join(sparsedir, fname), m)\n",
    "    \n",
    "    if idx in train_idx:\n",
    "        train_count+= 1\n",
    "    else:\n",
    "        test_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 177, 44, 44)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count,len(train_idx), test_count,len(test_idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 7, 0, 5, 1, 6, 8, 9, 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir, dataname+'-vocab.txt'), 'w') as f:\n",
    "    if node_labels is False:\n",
    "        nb_unique_node_labels = np.max(node_vocab)+1\n",
    "        \n",
    "    for i in range(nb_unique_node_labels):\n",
    "        f.write(str(i)+'\\n')\n",
    "    f.write(\"[CLS]\"+'\\n')\n",
    "    f.write(\"[MASK]\"+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir, dataname+'-vocab_label.txt'), 'w') as f:\n",
    "    for i in c.keys():\n",
    "        f.write(str(i)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
